# 1. 网络

网络就是可以进行数据发送与接收的网络节点的集合。



## 网络节点

每一个连接到网络的设备都可以称为一个网络节点，其中主要为计算机，当然也包括其他可以发送/接收网络数据的设备。



## 节点地址

对于接入网络的设备，需要通过网络进行数据的传输，这时它的数据需要传输到特定设备时，该如何在网络中查找特定设备并进行数据传输？

**网络地址**就是网络中不同设备的唯一标志的序列。

不同的网络，会以不同的方式进行地址分配。需要保证的是地址唯一。



## 网络传输

对于现有的计算机网络，都是通过数据包进行数据交换：流经网络的数据将被分为小的数据包进行发送。

每个数据包都单独处理，包含发送的来源地址及目的地地址。

网络通常用线缆连接，数据的变化：数据 -> 字节数据 -> 数据位 -> 电磁波。

所以网络的传输，实际传输的是数据位信息，我们需要解析数据位信息，获取数据包，组合成我们所需的字节、字符等数据信息



## 网络协议

由于网络传输的都是数据位信息，那么我们对于数据位信息的解析就需要有统一的标准，否则将无法理解接收的数据的含义。

这时就产生了协议，协议是计算机定义的数据通信的规则：包括数据的地址格式、数据如何分包等。

常用的协议有HTTP(超文本传输协议)等



# 2. 网络分层

通过前面对于网络的分析，我们可知网络主要用于进行数据位信息的传输。

但是对于数据位信息的传输方式包括电缆、光纤、wifi等等。并且对于不同的网络，其网络地址的分配方式不尽相同。其次对于数据分包、解析的不同协议，也是多种多样。

这样来看，对于一个普通的程序开发人员，是不可能去关注对于网络数据传输的各个细节。且对于不同的数据传输、网络寻址、数据分包、解析，它们之间的关联是十分复杂的。

为了对于开发人员、用户隐藏这种复杂性，我们将网络通信的不同方面抽象为了不同的网络层级，就产生了网络分层模型。

我们常用的网络分层模型就是：TCP/IP 网络模型



## TCP/IP 网络模型

对于TCP/IP 网络模型，实际上也有多种解释，此处我们分析为五层TCP/IP 网络模型：

- 应用层
- 传输层
- 网络层
- 数据链路层
- 物理层



### 应用层

应用层，是我们能直接接触的一层。

我们常用的计算机、手机的设备，都是使用设备中的软件应用为我们提供服务，这些应用软件，都属于应用层。

对于应用层而言，它不关心底层数据的传输，而关注与数据的产生与使用。

应用层将用户关心的数据，基于不同协议，产生对应的数据包，对于数据传输工作，统一交由传输层及其下层进行处理。

应用层**常用的协议**有：http协议、ftp协议（文件传输协议）、snmp（网络管理协议）、telnet （远程登录协议 ）、smtp（简单邮件传输协议）、dns（域名解析）



### 传输层

应用软件产生的数据包将传递给传输层进行数据传输工作，传输层将决定数据包的传输方式。

传输层的两种**传输方式**：

- TCP
- UDP

应用层传递给传输层的数据包是完整的，包含所传输的所有数据。

但是对于传输层而言，直接将完整的数据包进行传输，可能数据包过大。所以如果数据包大小超过限制时，将会将数据包进行**分块处理**。

对于TCP协议而言，如果数据包大小超过MSS(TCP协议最大报文段长度)，将会对数据包进行分块，每个数据块称为一个TCP段。

对于一个网络节点设备，它可能不仅仅是运行一个应用，那么传输层将如何识别设备中的对应应用呢？

此处使用**端口号**来区分不同的设备应用，传输层传输的数据将包含目标应用的端口，所以传输层可以将数据包准确的传递给应用层应用。



### 网络层

对于网络上的节点，它们不是一一对应连接的，往往数据包的传输将经过网络上的多个节点层层传递，才能到达目的地。

对于一个活泼的网络而言，同时传输的数据包是大量的、分散的，对于同一应用层数据包经过传输层分块后，并不一定会一起进行传输，那么我们将如何确定网络上的某一个数据包的目的地呢？

网络层就是用于处理这个问题的，网络层常用的协议有：IP协议、ICMP协议、ARP协议(通过分析ip地址得出物理mac地址)

通过上述协议，我们可以定位一个包的目标节点，从而将数据包传输到对应的节点设备。

⽹络层最常使⽤的是 IP 协议（Internet Protocol），IP 协议会将传输层的报⽂作为数据部分，再加上 IP 包头组装 成 IP 报⽂，如果 IP 报⽂⼤⼩超过 MTU（以太⽹中⼀般为 1500 字节）就会再次进⾏分⽚，得到⼀个即将发送到⽹ 络的 IP 报⽂。



### 数据链路层

对于网络层而言，常用的**IP地址用于标志数据包的最终目的地**(目标节点设备)，但是网络是复杂的，不会说知道了目标节点设备后，就可以直接将数据包发送过去，而是期间会经过多个路由设备(常用的是路由器)进行转发。

对于一个路由器而言，它接收到一个数据包后，将要将其发送到下一个路由器，此时需要通过路由表计算出下一个路由器的IP地址。

那么如何通过IP地址知道具体是哪个路由设备呢？

这就需要通过数据链路层来标志路由设备，它主要为⽹络层提供链路级别传输的服务。

每一个节点设备的网卡都有一个唯一的MAC地址，用于标志唯一的设备网卡。路由器通过路由表计算出下一个路由器的IP地址，再通过ARP协议计算出其对应的MAC地址，就可以知道具体的路由设备了。

所以，IP 协议的寻址作⽤是告诉我们去往下⼀个⽬的地该朝哪个⽅向⾛，路由则是根据「下⼀个⽬的地」选择路 径。寻址更像在导航，路由更像在操作⽅向盘。



### 物理层

通过前面的层级，我们已经确定了数据包的发送方向，此时将进行数据传输工作。对于不同的物理传输方式，物理层将数据包解析为对应的信号进行信息传递。

物理层就是为数据链路层进行数据的二进制传递工作的。



## 分层数据流通方向

![image-20211012185428082](D:\学习整理\summarize\网编相关\网编知识图片\网络分层数据流通方向)



# 3. MAC地址和IP地址

## MAC地址

MAC（Media Access Control，介质访问控制）地址，或称为物理地址，也叫硬件地址，用来定义网络设备的位置，MAC地址是网卡出厂时设定的，是固定的（但可以通过在设备管理器中或注册表等方式修改，同一网段内的MAC地址必须唯一）。

MAC地址采用十六进制数表示，长度是6个字节（48位），分为前24位和后24位。

- 前24位叫做组织唯一标志符（Organizationally Unique Identifier，即OUI），是由IEEE的注册管理机构给不同厂家分配的代码，区分了不同的厂家。
- 后24位是由厂家自己分配的，称为扩展标识符。同一个厂家生产的网卡中MAC地址后24位是不同的。

MAC地址工作于数据链路层，用于给交换机/路由器定位工作区域的节点设备，判断数据传输方向。



## IP地址

IP地址(Internet Protocol Address)，是一种在Internet上的给主机统一编址的地址格式，也称为网络协议（IP协议）地址。

它为计算机网络中的每一个节点设备分配一个逻辑地址，常见的IP地址分为IPv4/IPv6两大类。



### IPv4

IPv4地址由32位二进制数组成，分为4段（4个字节），每一段为8位二进制数（1个字节），每一段8位二进制，中间使用英文的标点符号“.”隔开

由于二进制不利于记忆，所以将每段转换为10进制，大小为0 ~ 255。IP地址的这种表示法叫做“**点分十进制表示法**”。



### IP地址的组成

```
IP地址 = 网络部分 + 主机部分

例：IP地址：192.168.1.100，其中网络部分为：192.168.1，主机部分为：100
```



### 本地回环地址

在IP地址分配时，存在一些特殊的IP地址，它们用于内部使用，不允许加入全球网络，它们有特殊开头：

- 10.
- 172.16.
- 172.31.
- 192.168.

除了这些，还存在一种特殊的IP地址，就是以127开头的IPv4地址，它们总表示本地回环地址。

其中常见的就是：127.0.0.1



## 网段和子网掩码

### IP地址分类

为了便于寻址和层次化的构造网络，IP地址被分为A、B、C、D、E五类，用于商业的有A、B、C三类

这些地址分类的特点为前面存在固定的网络号码，剩余其他的由任意的主机地址组成。

```
网络地址：固定分配地址
主机地址：自行分配地址

例：01111111.????????.????????.????????，? 位置可任意填0/1
   其中第一字节 01111111 为网络地址，后三字节 ????????.????????.???????? 为主机地址

A类地址：网络地址由一字节组成，其他三字节为主机地址，且第一字节第一位固定为0(二进制)。
	例：111.xxx.xxx.xxx，转换为二进制表示就是 01101111.????????.????????.???????? ，第一字节第一位为0
	   
B类地址：网络地址由二字节组成，其他二字节为主机地址，且第一字节前两位固定为10(二进制)。
	例：128.81.xxx.xxx，转换为二进制表示就是 10000000.01010001.????????.????????，第一字节前两位为10
	
C类地址：网络地址由三字节组成，其他一字节为主机地址，且第一字节前三位固定为110(二进制)	
	例：192.168.92.xxx，转换为二进制表示就是 11000000.10100110.01011100.????????，第一字节前三位为110
```

![image-20211012210801841](D:\学习整理\summarize\网编相关\网编知识图片\IP地址分类)



### 子网与子网掩码

#### 子网

如果仅仅安装上述IP地址分类来分配地址，那么就存在许多问题：

- **地址利用率低**：对于B类地址而言，可以连接的最大主机数为65534，而对于C类地址来说，可以连接的最大主机数仅有254。那么如果假如一个单位仅需要连接500个主机，申请C类地址明显不够，而申请B类地址，又将大大浪费IP地址
- **路由管理困难**：如果为每一个物理网络都分配一个网络号，将导致路由表过大，造成路由表管理成本增加、查询效率低
- **网络号浪费**：如果一个单位申请了一个网络号，他想将多余的IP地址再分配给下属单位时，将要申请新的网络号，此时导致网络号浪费

此时，为了解决上述问题，就产生了子网的概念。

**一个子网，其包含的网络IP地址段，就叫做一个网段。判断两个IP地址是否相同网段，实质就是判断其是否所属同一子网。**

**路由器连接不同网段，负责不同网段之间的数据转发，交换机连接的是同一网段的计算机。**



#### 子网划分

子网实质是在IP分类的基础上，其中网络地址不变，将主机地址进行细化，划分为多个子网，对外表现还是一个原有的网络。

```
此时IP地址为：网络地址 + 子网地址 + 主机地址

举例说明：
1. 假如一个B类地址为145.13.xxx.xxx，其中网络地址固定为145.13.
2. 此时原有的主机地址为 16 位，假如子网地址分配为 8 位，那么剩余 主机地址为8位 
3. 假定 一个子网分配为 145.13.3.xxx ，其中子网的一个节点设备的IP地址为 145.13.3.10

此时我要将数据传输到节点设备 145.13.3.10 上：
1. 在主网中找到分配B类地址为 145.13.xxx.xxx 的设备(实际是路由器)
2. 通过该路由器找到子网设备 145.13.3.xxx
3. 通过子网设备，找到对应目标节点设备 145.13.3.10
```

 **此时，可以将网络号和子网号统一为网络标识。**



#### 子网掩码

当数据到达主网设备路由器时，该如何确定数据该发送到哪一个子网上？

为了快速确定 IP地址对应的子网，就设计出了子网掩码。

子网掩码是一个32位的二进制数据，将子网掩码与IP地址进行**按位与**操作，即可获取其对应子网

```
举例说明：
1. 目标IP地址 145.13.3.10，转换为二进制为：10010001.00001101.00000011.00001010
2. 子网掩码为：11111111.11111111.11111111.00000000
3. 得到的子网IP为：10010001.00001101.00000011.00000000，转换为十进制为：145.13.3.00
```

**所以，在路由表中既要有目的网络地址，也要有该网络的子网掩码。才能判断目的IP是否与目的网络地址对应。**



##### 如何确定子网掩码？

```
如果申请的是B类网络，划分子网时，子网地址分配8位，则主机地址为8位
假设网络地址为145.13.

由于主机位为8位，则表示一个子网IP地址最多可以分配254台主机
1. 假如此时，我所需主机数小于254，则子网掩码可以直接设置为255.255.255.0。那么每个子网IP都是独立的
2. 假如此时，我所需主机数为600，超过254，那么该如何设置子网掩码？

主机数为600，表示可以使用三个子网IP对应网段设置一个大网段
假定：
1. 分配三个子网IP为：145.13.0.xxx，145.13.2.xxx，145.13.3.xxx，满足主机数需求
2. 将上述三个子网IP解析为二进制，保留网络地址和子网地址位，分别为
	11000000 10101000 00000000
	11000000 10101000 00000001
	11000000 10101000 00000010

可以发现，对应于上述数据，前22位相同，则此时可以设置子网掩码为
	11111111 11111111 11111100 00000000
转换为十进制为
	255.255.252.0
```



# 4. DNS域名解析

使用IP地址进行网站访问存在以下问题：

- IP地址不利于记忆
- 网站的IP地址可能更换

所以就发明了域名，并**通过域名解析协议（DNS，Domain Name System）来将域名和 IP 地址相互映射**，使人更方便地访问互联网，而不用去记住能够被机器直接读取的 IP 地址数串。

将域名映射成 IP 地址称为正向解析，将 IP 地址映射成域名称为反向解析。

DNS 协议可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。但**大多数情况下 DNS 都使用 UDP 进行传输**。



参考：https://segmentfault.com/a/1190000039039275



## 域名层级

域名其实是具有一定的层次结构的，从上到下依次为：**根域名**、**顶级域名**（top level domain，TLD）、**二级域名**、（三级域名）

```
例如：www.baidu.com

三级域名：www
二级域名：baidu
顶级域名：com
```



## 域名服务器

域名服务器是指管理域名的主机和相应的软件，它可以管理所在分层的域的相关信息，一个域名服务器所负责管里的分层叫作 **区 (ZONE)**。

域名的每层都设有一个域名服务器：

- 根域名服务器：**保存所有的顶级域名服务器的地址**
- 顶级域名服务器：**管理注册在该顶级域名下的所有二级域名**
- 权限域名服务器：权限域名服务器就是负责管理一个“**区**”的域名服务器



## 域名查询

域名的查询是进过下面层级的

- 浏览器域名缓存
- 操作系统域名缓存(实际就是`hosts`文件存储)
- 域名服务器



# 5.  Socket编程

## 原生Socket类

| 类名                       | 描述                                   |
| -------------------------- | -------------------------------------- |
| java.net.Socket            | 客户端套接字                           |
| java.net.ServerSocket      | 服务器套接字                           |
| java.net.InetAddress       | 用来表示IP地址的高级表示               |
| java.net.InetSocketAddress | 实现 IP 套接字地址（IP 地址 + 端口号） |
| java.net.DatagramSocket    | 用于发送和接收数据报包的套接字。       |
| java.net.DatagramPacket    | 表示数据报包                           |



## Socket通信协议

`Socket`通信是与传输层TCP/IP协议紧密关联，Socket通信协议有以下两种：

- `TCP`协议
- `UDP`协议



### TCP协议

TCP协议是一种有连接的协议，使用应用程序之前，必须先建立TCP连接。所以每次在进行通信之前那，我们需要先建立Socket连接，一个socket作为服务端监听请求，一个socket作为客户端进行连接请求。只有双方建立连接好以后，双方才可以通信



### UDP协议

UDP协议是一种无连接的协议，也称为数据报协议。每次发送数据报时，需要同时发送本机的socket描述符(就是上面所说的套接字描述符)和接收端的socket描述符。所以，每次通信都要发送额外的数据。



### 两种协议区别

在UDP中，每次发送数据报，需要附上本机的socket描述符和接收端的socket描述符.而TCP是基于连接的协议，在通信的socket之间需要在通信之前建立连接，即**TCP的三次握手**，，因此建立连接会有一定耗时

在UDP中，数据报数据在大小有64KB的限制。而TCP不存在这样的限制，一旦TCP通信的socket对建立连接，他们通信类似IO流。

UDP是不可靠的协议，发送的数据报不一定会按照其发送顺序被接收端的socket接收。而TCP是一种可靠的协议。接收端收到的包的顺序和包在发送端的顺序大体一致(这里不讨论丢包的情况)



## 代码实现

对于不同的协议，其代码实现方式也是不同的



### TCP协议

#### 服务端

服务器端主要使用`ServerSocket`创建服务器套接字，并使用线程池实现多客户端服务

```java
@Test
public void serverTest() throws Exception{
    // 1. 初始化服务socket，绑定端口
    ServerSocket serverSocket = new ServerSocket(8080);

    // 2. 创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(100);

    // 3. 循环保持服务端持续工作，否则报错：Connection reset
    while (true) {
        // 4. 阻塞监听连接
        Socket accept = serverSocket.accept();

        // 5. 接受到客户端连接，开启线程处理任务
        executorService.submit(() -> {
            System.out.println(Thread.currentThread().getName());

            BufferedReader reader = null;
            BufferedWriter writer = null;
            try {
                // 6. 获取客户端输入流
                reader = new BufferedReader(new InputStreamReader(accept.getInputStream()));
                // 7. 获取客户端输出流
                writer = new BufferedWriter(new OutputStreamWriter(accept.getOutputStream()));

                // 8. 响应客户端，表示接收到响应
                System.out.println("接到访问");
                writer.write("欢迎访问本服务器");
                writer.newLine();
                writer.flush();

                // 9. 循环获取客户端发送信息
                String str;
                while ((str = reader.readLine()) != null) {
                    System.out.println(str);
                }

                // 10.  响应客户端，表示处理完毕
                System.out.println("访问结束");
                writer.write("本次服务结束，欢迎下次光临");
                writer.newLine();
                writer.flush();

            } catch (IOException e) {
                e.printStackTrace();
            } finally {
                try {
                    reader.close();
                    writer.close();
                    accept.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }

        });
    }
}
```



#### 客户端

```java
@Test
public void clientTest() throws Exception {
    // 1. 创建Socket连接，连接到目标IP 、 端口对应的服务应用
    Socket socket = new Socket("127.0.0.1", 8080);

    // 2. 获取服务端输出流
    BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(socket.getOutputStream()));
    // 3. 获取服务端输入流
    BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream()));

    // 4. 向服务端发送信息
    writer.write("真实乏味");
    writer.newLine();
    writer.flush();

    writer.write("确实哦");
    writer.newLine();
    writer.flush();

    // 5. 由于服务端使用BufferedReader.readLine接受消息，所以使用shutdownOutput关闭连接，防止reader.readLine阻塞
    socket.shutdownOutput();

    // 6. 循环获取服务端响应数据
    String str;
    while ((str = reader.readLine()) != null) {
        System.out.println(str);
    }

    reader.close();
    writer.close();
    socket.close();
}
```



#### BufferedReader的注意点

我们通常使用`BufferedReader`包装底层字节流`InputStream`，因为使用`BufferedReader#readLine`比使用字节读取方便，但是`BufferedReader#readLine`使用时有需要我们注意的地方：

- 在`Socket`编程时使用`readLine`函数，但是`readLine`是阻塞式的，也就是说如果`readLine`读取不到数据，会一直阻塞，而不会返回`null`
- 如果使用`readLine`方法时，需要使用`String`类型变量接收读取信息，否则无法再次读取这行内容
- `readLine`方法通过`\n、\r、\r\n`表示一行的终止，它会将一行数据进行读取，否则将一直阻塞
- `readLine`只有在数据流发生异常/网络对端对应的输入流关闭时，才会返回`null`值，表示读取结束



### UDP协议

#### 服务端

```java
@Test
public void udpServerTest() throws Exception {
    // 1. 创建服务端DatagramSocket，绑定服务端口
    DatagramSocket socket = new DatagramSocket(8080);

    // 2. 创建数据包，用于接受客户端发送的数据包
    // 2.1 创建字节数据，用于数据保存
    byte[] data = new byte[1024];
    DatagramPacket packet = new DatagramPacket(data, data.length);

    while (true) {
        // 3. 阻塞等待客户端发送的数据包
        socket.receive(packet);

        // 4. 读取包中数据
        // packet.getLength() 会获取包中具体数据长度
        System.out.println(new String(data, 0, packet.getLength()));

        // 5. 向客户端响应数据
        // 5.1 获取客户端地址
        InetAddress address = packet.getAddress();

        // 5.2 获取客户端端口
        int port = packet.getPort();

        // 5.3 创建响应数据包， 并指定目的地：address/port
        byte[] bytes = "欢迎下次光临".getBytes();
        DatagramPacket respPackage = new DatagramPacket(bytes, bytes.length, address, port);

        // 5.4 数据包发送
        socket.send(respPackage);
    }
}
```



#### 客户端

```java
@Test
public void udpClientTest() throws Exception {
    // 1. 定义服务端地址
    InetAddress address = InetAddress.getByName("localhost");

    // 2. 定义服务端端口
    int port = 8080;

    // 3. 创建客户端DatagramSocket
    DatagramSocket socket = new DatagramSocket();

    // 4. 定义发送的数据包
    byte[] bytes = "满怀期待的一次访问".getBytes();
    DatagramPacket packet = new DatagramPacket(bytes, bytes.length, address, port);

    // 5. 发送数据包
    socket.send(packet);

    // 6. 接收服务端响应数据包
    // 6.1 创建数据包用于接收响应数据
    byte[] data = new byte[1024];
    DatagramPacket respPackage = new DatagramPacket(data, data.length);

    // 6.2 阻塞接收数据包
    socket.receive(respPackage);

    // 6.3 读取包中数据
    // packet.getLength() 会获取包中具体数据长度
    System.out.println(new String(data, 0, packet.getLength()));

    // 6.关闭资源
    socket.close();
}
```





# Nginx

nginx （engine x）是一个可以作为HTTP WEB服务器、反向代理服务器、邮件代理服务器和一个通用的TCP / UDP代理服务器（1.9.0版本后）的多功能架构组件，同时也可以提供一定的缓存服务功能

`nginx`的优点：

- 支持高并发，能支持几万并发连接



## Nginx配置文件

`Nginx`的安装我们不予多说，下载网址：http://nginx.org/，在`nginx`安装后，我们需要关注的文件夹有：

- `/etc/nginx/conf.d/`：子配置项的存储位置
  - `/etc/nginx/nginx.conf`：主配置文件
- `/usr/share/nginx/html/`：通常用于存放静态资源，也可以根据自己习惯选择静态文件存储位置



我们主要分析一下`nginx.conf`主配置文件，它主要包括以下部分：

| 配置区域   | 说明                                                         |
| ---------- | ------------------------------------------------------------ |
| main块     | 配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。 |
| events块   | 配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。 |
| http块     | 可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 |
| upstream块 | 配置HTTP负载均衡器分配流量到几个应用程序服务器。             |
| server块   | 配置虚拟主机的相关参数，一个http中可以有多个server。         |
| location块 | 配置请求的路由，以及允许根据用户请求的URI来匹配指定的各location以进行访问配置；匹配到时，将被location块中的配置所处理。 |



**文件具体细节如下**：

```bash
######Nginx配置文件nginx.conf中文详解#####

#定义Nginx运行的用户和用户组
user www www;

#nginx进程数，建议设置为等于CPU总核心数。
worker_processes 4;
 
#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]
error_log /opt/nginx/logs/error.log info;

#进程pid文件
pid /opt/nginx/logs/nginx.pid;

#指定进程可以打开的最大描述符：数目
#工作模式与连接数上限
#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。
#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。
#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。
worker_rlimit_nofile 65535;


events
{
    #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型
    #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。
    #补充说明：
    #与apache相类，nginx针对不同的操作系统，有不同的事件模型
    #A）标准事件模型
    #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll
    #B）高效事件模型
    #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。
    #Epoll：使用于Linux内核2.6版本及以后的系统。
    #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。
    #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。
    use epoll;

    #单个进程最大连接数（最大连接数=连接数*进程数）
    #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。
    worker_connections 65535;

    #keepalive超时时间。
    keepalive_timeout 60;

    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。
    #分页大小可以用命令getconf PAGESIZE 取得。
    #[root@web001 ~]# getconf PAGESIZE
    #4096
    #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。
    client_header_buffer_size 4k;

    #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。
    open_file_cache max=65535 inactive=60s;

    #这个是指多长时间检查一次缓存的有效信息。
    #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.
    open_file_cache_valid 80s;

    #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。
    #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location  这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.
    open_file_cache_min_uses 1;
    
    #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误.
    open_file_cache_errors on;
}
 
#设定http服务器，利用它的反向代理功能提供负载均衡支持
http
{
    #文件扩展名与文件类型映射表
    include mime.types;

    #默认文件类型
    default_type application/octet-stream;

    #默认编码
    #charset utf-8;

    #服务器名字的hash表大小
    #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.
    server_names_hash_bucket_size 128;

    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。
    client_header_buffer_size 32k;

    #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。
    large_client_header_buffers 4 64k;

    #设定通过nginx上传文件的大小
    client_max_body_size 8m;

    #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
    #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。
    sendfile on;

    #开启目录列表访问，合适下载服务器，默认关闭。
    autoindex on;

    #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用
    tcp_nopush on;
     
    tcp_nodelay on;

    #长连接超时时间，单位是秒
    keepalive_timeout 120;

    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。
    fastcgi_connect_timeout 300;
    fastcgi_send_timeout 300;
    fastcgi_read_timeout 300;
    fastcgi_buffer_size 64k;
    fastcgi_buffers 4 64k;
    fastcgi_busy_buffers_size 128k;
    fastcgi_temp_file_write_size 128k;

    #gzip模块设置
    gzip on; #开启gzip压缩输出
    gzip_min_length 1k;    #最小压缩文件大小
    gzip_buffers 4 16k;    #压缩缓冲区
    gzip_http_version 1.0;    #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
    gzip_comp_level 2;    #压缩等级
    gzip_types text/plain application/x-javascript text/css application/xml;    #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。
    gzip_vary on;

    #开启限制IP连接数的时候需要使用
    #limit_zone crawler $binary_remote_addr 10m;

    #负载均衡配置
    upstream jh.w3cschool.cn {
     
        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。
        server 192.168.80.121:80 weight=3;
        server 192.168.80.122:80 weight=2;
        server 192.168.80.123:80 weight=3;

        #nginx的upstream目前支持4种方式的分配
        #1、轮询（默认）
        #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
        #2、weight
        #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
        #例如：
        #upstream bakend {
        #    server 192.168.0.14 weight=10;
        #    server 192.168.0.15 weight=10;
        #}
        #2、ip_hash
        #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
        #例如：
        #upstream bakend {
        #    ip_hash;
        #    server 192.168.0.14:88;
        #    server 192.168.0.15:80;
        #}
        #3、fair（第三方）
        #按后端服务器的响应时间来分配请求，响应时间短的优先分配。
        #upstream backend {
        #    server server1;
        #    server server2;
        #    fair;
        #}
        #4、url_hash（第三方）
        #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
        #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法
        #upstream backend {
        #    server squid1:3128;
        #    server squid2:3128;
        #    hash $request_uri;
        #    hash_method crc32;
        #}

        #tips:
        #upstream bakend{#定义负载均衡设备的Ip及设备状态}{
        #    ip_hash;
        #    server 127.0.0.1:9090 down;
        #    server 127.0.0.1:8080 weight=2;
        #    server 127.0.0.1:6060;
        #    server 127.0.0.1:7070 backup;
        #}
        #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;

        #每个设备的状态设置为:
        #1.down表示单前的server暂时不参与负载
        #2.weight为weight越大，负载的权重就越大。
        #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误
        #4.fail_timeout:max_fails次失败后，暂停的时间。
        #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。

        #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。
        #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug
        #client_body_temp_path设置记录文件的目录 可以设置最多3层目录
        #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡
    }
     
     
     
    #虚拟主机的配置
    server
    {
        #监听端口
        listen 80;

        #域名可以有多个，用空格隔开
        server_name www.w3cschool.cn w3cschool.cn;
        index index.html index.htm index.php;
        root /data/www/w3cschool;

        #对******进行负载均衡
        location ~ .*.(php|php5)?$
        {
            fastcgi_pass 127.0.0.1:9000;
            fastcgi_index index.php;
            include fastcgi.conf;
        }
         
        #图片缓存时间设置
        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$
        {
            expires 10d;
        }
         
        #JS和CSS缓存时间设置
        location ~ .*.(js|css)?$
        {
            expires 1h;
        }
         
        #日志格式设定
        #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；
        #$remote_user：用来记录客户端用户名称；
        #$time_local： 用来记录访问时间与时区；
        #$request： 用来记录请求的url与http协议；
        #$status： 用来记录请求状态；成功是200，
        #$body_bytes_sent ：记录发送给客户端文件主体内容大小；
        #$http_referer：用来记录从那个页面链接访问过来的；
        #$http_user_agent：记录客户浏览器的相关信息；
        #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。
        log_format access '$remote_addr - $remote_user [$time_local] "$request" '
        '$status $body_bytes_sent "$http_referer" '
        '"$http_user_agent" $http_x_forwarded_for';
         
        #定义本虚拟主机的访问日志
        access_log  /usr/local/nginx/logs/host.access.log  main;
        access_log  /usr/local/nginx/logs/host.access.404.log  log404;
         
        #对 "/" 启用反向代理
        location / {
            proxy_pass http://127.0.0.1:88;
            proxy_redirect off;
            proxy_set_header X-Real-IP $remote_addr;
             
            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
             
            #以下是一些反向代理的配置，可选。
            proxy_set_header Host $host;

            #允许客户端请求的最大单文件字节数
            client_max_body_size 10m;

            #缓冲区代理缓冲用户端请求的最大字节数，
            #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。
            #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误
            client_body_buffer_size 128k;

            #表示使nginx阻止HTTP应答代码为400或者更高的应答。
            proxy_intercept_errors on;

            #后端服务器连接的超时时间_发起握手等候响应超时时间
            #nginx跟后端服务器连接超时时间(代理连接超时)
            proxy_connect_timeout 90;

            #后端服务器数据回传时间(代理发送超时)
            #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据
            proxy_send_timeout 90;

            #连接成功后，后端服务器响应时间(代理接收超时)
            #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）
            proxy_read_timeout 90;

            #设置代理服务器（nginx）保存用户头信息的缓冲区大小
            #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小
            proxy_buffer_size 4k;

            #proxy_buffers缓冲区，网页平均在32k以下的设置
            #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k
            proxy_buffers 4 32k;

            #高负荷下缓冲大小（proxy_buffers*2）
            proxy_busy_buffers_size 64k;

            #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长
            #设定缓存文件夹大小，大于这个值，将从upstream服务器传
            proxy_temp_file_write_size 64k;
        }
         
         
        #设定查看Nginx状态的地址
        location /NginxStatus {
            stub_status on;
            access_log on;
            auth_basic "NginxStatus";
            auth_basic_user_file confpasswd;
            #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。
        }
         
        #本地动静分离反向代理配置
        #所有jsp的页面均交由tomcat或resin处理
        location ~ .(jsp|jspx|do)?$ {
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_pass http://127.0.0.1:8080;
        }
         
        #所有静态文件由nginx直接读取不经过tomcat或resin
        location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|
        pdf|xls|mp3|wma)$
        {
            expires 15d; 
        }
         
        location ~ .*.(js|css)?$
        {
            expires 1h;
        }
    }
}
######Nginx配置文件nginx.conf中文详解#####
```



## Nginx常用命令

```
nginx -s reload  # 向主进程发送信号，重新加载配置文件，热重启
nginx -s reopen	 # 重启 Nginx
nginx -s stop    # 快速关闭
nginx -s quit    # 等待工作进程处理完成后关闭
nginx -T         # 查看当前 Nginx 最终的配置
nginx -t -c <配置路径>    # 检查配置是否有问题，如果已经在配置目录，则不需要-c
```



## Nginx应用

### 正向代理

我们使用客户端浏览器访问服务端，通常是直接访问对应服务器。但是存储某些服务器我们无法访问，例如使用谷歌浏览器，无法访问部分服务器。

此时我们可以通过一个中间的代理服务器，帮我们进行请求的转发工作，由代理服务器访问目标服务器后，接收到目标服务器的响应，再转发给我们。

**正向代理是针对客户端的**

![image-20211014215540725](D:\学习整理\summarize\网编相关\网编知识图片\正向代理)

#### 文件配置

```bash
server{
	# 指定DNS服务器的IP地址
    resolver 8.8.8.8;
    
    # 超时时间（5秒）
    resolver_timeout 30s;	
    
    # 监听端口
    listen 8080;
    
    access_log  /var/log/nginx/reverse.access.log  main;
    error_log   /var/log/nginx/reverse.error.log  warn;
    
    # 拦截所有请求
    location / {
    	# 设置的代理服务器协议和地址
        proxy_pass http://$http_host$request_uri;
        # 配置缓存大小
        proxy_buffers 256 4k; 			
        # 关闭磁盘缓存读写减少I/O
        proxy_max_temp_file_size 0;			
        # 代理连接超时时间
        proxy_connect_timeout 30;			
        proxy_cache_valid 200 302 10m;
        proxy_cache_valid 301 1h;
        # 配置代理服务器缓存时间
        proxy_cache_valid any 1m;			
    }
}
```

由上述配置可知，`Nginx`的正向代理就是创建一个用于代理的**虚拟服务器**，在客户端浏览器发送请求后，虚拟服务器将拦截本机请求，并将**请求转发到配置的代理服务器**，由代理服务器进行服务的代理动作



### 反向代理

我们使用客户端浏览器访问目标服务器，在服务端，为了隐藏服务器地址或者使用多个服务器为我们提供服务，它对外公开的域名并不是对应真实服务器，而是对应的反向代理服务器，由反向代理服务器统一接收外界请求，再转发到真实服务器进行处理，最后获取到响应再返回到浏览器。

**反向代理是针对于服务端的**

![image-20211014220326148](D:\学习整理\summarize\网编相关\网编知识图片\反向代理)

对于反向代理而言，有以下特定：

- 客户端浏览器端无需任何配置
- 代理的动作对于客户端浏览器是隐藏的
- 真实服务器是不可见的
- `nginx` + `tomcat` 整体视为服务端



#### 文件配置

```bash
server {
	# 监听端口
    listen       80;
    # 监听地址
    server_name  192.168.4.32;   
	
	# 拦截请求
    location  /abc {
    	#/html目录  
        root html;  
        # 请求转向
        proxy_pass http://127.0.0.1:8080;  
        # 设置默认页    
        index  index.html index.htm;      
    }
    
    # 拦截请求
    location  /cfg {
    	#/html目录  
        root html;  
        # 请求转向
        proxy_pass http://127.0.0.1:8081;  
        # 设置默认页    
        index  index.html index.htm;      
    }
}  
```

由上述配置可知，`Nginx`的反向代理就是创建一个用于代理的**虚拟服务器**，这个虚拟服务器将拦截访问本机应用的请求，并将其转发到真实服务器。

**实质就是请求的拦截转发**





### 负载均衡

负载均衡有点类似于反向代理，反向代理常用于根据不同的访问路径，将请求转发到不同的服务器。

而负载均衡，通常是对于相同的访问路径，常规是对应单个服务器，而如果访问量过大，导致单个服务器无法满足需求时，需要扩展多个服务器。

这些对于客户端来说是隐藏的。



#### 文件配置

```bash
http {
    # upstream 设置负载均衡，对应服务 xxx
    upstream xxx.com{
        #保证每个访客固定访问一个后端服务器
        ip_hash;    
        # server：可配置多个服务器用于服务处理
        # weight：可配置权重，默认权重为1，权重越大，处理请求越多
        server 192.168.12.100:5000 weight=1;
        server 192.168.12.101:5000;
    }

    server {
        # 监听端口
        listen       80;
        # 监听地址
        server_name  192.168.4.32;   

        # 拦截请求
        location  / {
            # 请求转向到负载均衡服务器
            proxy_pass http://xxx.com;
        }
    }  
}
```

由上述配置可知，负载均衡是通过`upstream`创建一个虚拟服务器，拦截请求并转发到对应的工作服务器。



#### 负载均衡策略

负载均衡对于请求分发有多种策略，下面我们一一分析



##### 轮询

 所有请求按照时间顺序地轮流分配到应用服务器上，它可以均衡的将负载分散在后端服务器上，但是并不关心后端服务器的连接数和系统负载，它是`默认`的负载均衡策略。

在轮序中如果服务器宕机了会自动移除服务器。一般用于后端服务器性能均等的情况下。

```bash
upstream xx.com{
	server 192.168.12.100:5000 fail_timeout=2s max_fails=1;
	server 192.168.12.101:5000 fail_timeout=2s max_fails=1;
}
```



##### 权重weight

在轮询算法的基础上指定轮询的概率。权重越高被分配的记录越大，适合服务器硬件配置有一定差距的情况

```bash
upstream xx.com{
	server 192.168.12.100:5000 weight=1;
	server 192.168.12.101:5000 weight=1;
	server 192.168.12.101:5000 weight=3;
}
```



##### ip_hash

通过对IP的Hash值进行计算然后选择分配的服务器。

这个方法可以使客户端的请求发送到相同的服务器以保证session会话，并且可以使用权重。

```bash
upstream xx.com{
    ip_hash;    #保证每个访客固定访问一个后端服务器
    server localhost:8080   weight=2; 
    server localhost:8081;  
    server localhost:8082;  
    server localhost:8083   max_fails=3 fail_timeout=20s;  
}

```



**注意**：

- 使用IP_Hash需要Nginx是最前端的服务器，否则无法获取到正确的客户端IP
- 如果在IP_Hash的Nginx服务器之后还有其他的负载均衡，那么具体请求落在某一台服务器就无法确定了



### 动静分离

通常我们将静态文件打包到`Tomcat`的`Web`应用中，所以访问静态资源也是需要访问`Tomcat`服务器。

使用动静分离就是将静态文件保存到`Nginx`服务器中，在客户端访问请求静态资源时，无需由`Nginx`将请求转发到`Tomcat`服务器再进行资源获取，而是由`Nginx`服务器直接返回静态资源，由此减少`Tomcat`服务器压力。



#### 静态文件部署

可以定义静态文件夹用于存储静态资源：

- 名称自取，通常为`static`
- 与`conf`文件夹同级，也可以自定义



#### 文件配置

```bash
server {
	listen 8080;
	server_name localhost;
	
	# 拦截静态资源访问
	location ~ .*\.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)${
		# 用 root 表示访问的根路径
		# 如下配置表示到static目录中查询目标静态资源
		root static;
	}
}

# 例：
	# 在static文件夹中放置 index.html
	# 访问路径：http://localhost:8080/index.html
```



## Nginx底层进程机制

Nginx启动后，以daemon多进程⽅式在后台运⾏，包括⼀个Master进程和多个Worker进程，Master 进程是领导，是⽼⼤，Worker进程是⼲活的⼩弟。

- master进程：主要是管理worker进程。⽐如： 接收外界信号向各worker进程发送信号(./nginx -s reload) 监控worker进程的运⾏状态，当worker进程异常退出后Master进程会⾃动重新启动新的 worker进程等 
- worker进程：worker进程具体处理⽹络请求。多个worker进程之间是对等的，他们同等竞争来⾃客户端的请 求，各进程互相之间是独⽴的。⼀个请求，只可能在⼀个worker进程中处理，⼀个worker进程， 不可能处理其它进程的请求。worker进程的个数是可以设置的，⼀般设置与机器cpu核数⼀致。



### reload处理说明

- master进程对配置⽂件进⾏语法检查 
- 尝试配置（⽐如修改了监听端⼝，那就尝试分配新的监听端⼝）
- 尝试成功则使⽤新的配置，新建worker进程
- 新建成功，给旧的worker进程发送关闭消息
- 旧的worker进程收到信号会继续服务，直到把当前进程接收到的请求处理完毕后关闭 所以reload之后worker进程pid是发⽣了变化的



### worker进程请求处理说明

例如，我们监听9003端⼝，⼀个请求到来时，如果有多个worker进程，那么每个worker进程都有 可能处理这个链接。

- master进程创建之后，会建⽴好需要监听的的socket，然后从master进程再fork出多个 worker进程。所以，所有worker进程的监听描述符listenfd在新连接到来时都变得可读
- nginx使⽤互斥锁来保证只有⼀个workder进程能够处理请求，拿到互斥锁的那个进程注册 listenfd读事件，在读事件⾥调⽤accept接受该连接，然后解析、处理、返回客户端



### nginx多进程模型好处

- 每个worker进程都是独⽴的，不需要加锁，节省开销
- 每个worker进程都是独⽴的，互不影响，⼀个异常结束，其他的照样能提供服务
- 多进程模型为reload热部署机制提供了⽀撑